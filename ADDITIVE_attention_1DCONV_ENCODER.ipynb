{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hICYYFU8yBlhkFuURrkf5nSqpt5FaRlg","timestamp":1683002107119},{"file_id":"146G3uOG8AEQ_8VY8Pin9KS3ih8mrf9kK","timestamp":1682966623972},{"file_id":"1t2mcGWPRHzSBvY-2EFxbmfzP8hTiYtGl","timestamp":1682872912866}],"authorship_tag":"ABX9TyNVhP9WjtPAlP2umE7vdHwq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext\n","import torch.nn.functional as F\n","import unicodedata\n","import io\n","import json\n","import re\n","from google.colab import files\n"],"metadata":{"id":"0Qh30KRGM8vd","executionInfo":{"status":"ok","timestamp":1683049741626,"user_tz":-330,"elapsed":762,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKMNy3TvM7_h","executionInfo":{"status":"ok","timestamp":1683049743072,"user_tz":-330,"elapsed":627,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"de1dcc4c-a5ec-4826-aece-cd85b6750ed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-02 17:49:02--  https://raw.githubusercontent.com/nitinpunjabi/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5518306 (5.3M) [text/plain]\n","Saving to: ‘hun_eng_pairs_train.txt.1’\n","\n","hun_eng_pairs_train 100%[===================>]   5.26M  --.-KB/s    in 0.08s   \n","\n","2023-05-02 17:49:03 (68.3 MB/s) - ‘hun_eng_pairs_train.txt.1’ saved [5518306/5518306]\n","\n"]}],"source":["# Download the training set.\n","!wget https://raw.githubusercontent.com/nitinpunjabi/nlp-demystified/main/datasets/hun_eng_pairs/hun_eng_pairs_train.txt"]},{"cell_type":"code","source":["with open('hun_eng_pairs_train.txt') as file:\n","  train = [line.rstrip() for line in file]"],"metadata":{"id":"wryqNm8uNQ7E","executionInfo":{"status":"ok","timestamp":1683049743073,"user_tz":-330,"elapsed":10,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["train[:3],len(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FBsD6W3sNTTO","executionInfo":{"status":"ok","timestamp":1683049743073,"user_tz":-330,"elapsed":10,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"d39084c5-ac39-4f7b-dd14-4307a0062132"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([\"Teszek rá, mit mondasz!<sep>I don't care what you say.\",\n","  'Több olyan ember kell nekünk a csapatba, mint amilyen te vagy.<sep>We need more people like you on our team.',\n","  'Vigyázz a gyerekeimre!<sep>Take care of my children.'],\n"," 88647)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# Separate the input (Hungarian) and target (English) sentences into separate lists.\n","SEPARATOR = '<sep>'\n","train_input, train_target = map(list, zip(*[pair.split(SEPARATOR) for pair in train]))"],"metadata":{"id":"S_JTgNTJNXtR","executionInfo":{"status":"ok","timestamp":1683049744100,"user_tz":-330,"elapsed":1031,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["print(train_input[:3])\n","print(train_target[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7O2VlhLnNaJb","executionInfo":{"status":"ok","timestamp":1683049744100,"user_tz":-330,"elapsed":18,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"538a2004-a24d-43ba-d31b-746e04953ea4"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["['Teszek rá, mit mondasz!', 'Több olyan ember kell nekünk a csapatba, mint amilyen te vagy.', 'Vigyázz a gyerekeimre!']\n","[\"I don't care what you say.\", 'We need more people like you on our team.', 'Take care of my children.']\n"]}]},{"cell_type":"code","source":["print(\"\\u00E1\", \"\\u0061\\u0301\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sp7tu2IwNc7Z","executionInfo":{"status":"ok","timestamp":1683049744101,"user_tz":-330,"elapsed":15,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"5c4e2fc2-a50a-4ac8-f027-d3a73dca792a"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["á á\n"]}]},{"cell_type":"code","source":["import unicodedata\n","import re\n","# Unicode normalization\n","def normalize_unicode(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn')"],"metadata":{"id":"1edO9WObNh-M","executionInfo":{"status":"ok","timestamp":1683049744102,"user_tz":-330,"elapsed":8,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["def preprocess_sentence(s):\n","  s = normalize_unicode(s)\n","  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n","  s = re.sub(r'[\" \"]+', \" \", s)\n","  s = s.strip()\n","  return s"],"metadata":{"id":"1LmQXSaQNmNH","executionInfo":{"status":"ok","timestamp":1683049744103,"user_tz":-330,"elapsed":8,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# Preprocess both the source and target sentences.\n","train_preprocessed_input = [preprocess_sentence(s) for s in train_input]\n","train_preprocessed_target = [preprocess_sentence(s) for s in train_target]"],"metadata":{"id":"z9qsxphJNo0L","executionInfo":{"status":"ok","timestamp":1683049746786,"user_tz":-330,"elapsed":2691,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["train_preprocessed_input[:3],train_preprocessed_target[:3],"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBP_VBM2NrCs","executionInfo":{"status":"ok","timestamp":1683049746788,"user_tz":-330,"elapsed":44,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"0f4535f3-a18f-478f-830b-71ddfc9682b6"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['Teszek ra , mit mondasz !',\n","  'Tobb olyan ember kell nekunk a csapatba , mint amilyen te vagy .',\n","  'Vigyazz a gyerekeimre !'],\n"," [\"I don't care what you say .\",\n","  'We need more people like you on our team .',\n","  'Take care of my children .'])"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["def tag_target_sentences(sentences):\n","  tagged_sentences = map(lambda s: (' ').join(['<sos>', s, '<eos>']), sentences)\n","  return list(tagged_sentences)"],"metadata":{"id":"xWVk_FD9OgnI","executionInfo":{"status":"ok","timestamp":1683049746788,"user_tz":-330,"elapsed":40,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["train_tagged_preprocessed_target = tag_target_sentences(train_preprocessed_target)\n","train_tagged_preprocessed_target[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"o77jgwGmO0Fz","executionInfo":{"status":"ok","timestamp":1683049746789,"user_tz":-330,"elapsed":41,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"59c33836-b6c7-4ad7-9ba6-f9fc0c3801be"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<sos> I don't care what you say . <eos>\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["np.array(train_preprocessed_input).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpOcwFiGSVLI","executionInfo":{"status":"ok","timestamp":1683049746790,"user_tz":-330,"elapsed":38,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"9122cefb-eac4-4b52-aed2-00b6b558d28b"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(88647,)"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["def tokenise(line):\n","\tans=[]\n","\tpunc = [',', '.', '\"', \"'\", '/', '*', ',', '?', '!', '-', '\\n', '“', '”', '_', '&', '\\ufeff', '&', ';', \":\",'#','$','%','&','(',')','*','+','-','/',':',';','=','@',',','[\\\\]','^','_','`{|}~','\\t']\n","\tfor el in line:\n","\t\tif el in punc:\n","\t\t\tline = line.replace(el, \"\")\n","\t\n","\tline=line.lower()\n","\treturn line.split()\n","\traise NotImplementedError"],"metadata":{"id":"yunB_TA8QcMg","executionInfo":{"status":"ok","timestamp":1683049746791,"user_tz":-330,"elapsed":34,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["inp=np.array\n","a=tokenise(train_preprocessed_target[1])\n","a=np.array([a])\n","a.reshape(9,1)\n","a[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hf176KukVRKn","executionInfo":{"status":"ok","timestamp":1683049746791,"user_tz":-330,"elapsed":33,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"32e4a123-60c2-4994-c16d-3eb08bf3c179"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['we', 'need', 'more', 'people', 'like', 'you', 'on', 'our', 'team'],\n","      dtype='<U6')"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["np.array([1,2,3]).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8rT5PQ0ZWIa","executionInfo":{"status":"ok","timestamp":1683049746792,"user_tz":-330,"elapsed":31,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"99e5fbfb-269f-4eed-94a4-d85d7683a7d8"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3,)"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["sent=np.array([tokenise(train_preprocessed_input[0])])\n","sent=np.append(sent,'<pad>')\n","len(sent[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lf77L12zaf-f","executionInfo":{"status":"ok","timestamp":1683049746792,"user_tz":-330,"elapsed":27,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"d59cc706-f610-4651-d10a-149ef96e3ff1"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["input=np.array([tokenise(train_preprocessed_input[0])])\n","pad=np.full((50-len(input[0])),'<pad>')\n","sent=np.concatenate((input.squeeze(0),pad),axis=0)"],"metadata":{"id":"ROvKtZqrbK2f","executionInfo":{"status":"ok","timestamp":1683049746793,"user_tz":-330,"elapsed":24,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["train_input=train_preprocessed_input[:1000]\n","train_target=train_tagged_preprocessed_target[:1000]\n","test_input=train_preprocessed_input[1000:1200]\n","test_target=train_tagged_preprocessed_target[1000:1200]"],"metadata":{"id":"iyqYkX79e_Bb","executionInfo":{"status":"ok","timestamp":1683049746794,"user_tz":-330,"elapsed":25,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["de_vocab=set()\n","for line in train_input:\n","  sent=np.array([tokenise(line)])\n","  for x in sent[0]:\n","    de_vocab.add(x)"],"metadata":{"id":"iIrEMP_XevCF","executionInfo":{"status":"ok","timestamp":1683049746795,"user_tz":-330,"elapsed":25,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["en_vocab=set()\n","for line in train_target:\n","  sent=np.array([tokenise(line)])\n","  for x in sent[0]:\n","    en_vocab.add(x)"],"metadata":{"id":"eceL3SL8nhY9","executionInfo":{"status":"ok","timestamp":1683049746795,"user_tz":-330,"elapsed":25,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["!pip install ordered-set\n","from ordered_set import OrderedSet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1PFFs86m1Zc","executionInfo":{"status":"ok","timestamp":1683049751664,"user_tz":-330,"elapsed":4894,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"cc3b7988-d468-4cc3-8ee6-764612d40c67"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (4.1.0)\n"]}]},{"cell_type":"code","source":["vg=list(de_vocab)\n","vg.insert(0,'<pad>')\n","de_vocab=OrderedSet(vg)\n","\n","ve=list(en_vocab)\n","ve.insert(0,'<pad>')\n","en_vocab=OrderedSet(ve)"],"metadata":{"id":"bqlUVckom3zm","executionInfo":{"status":"ok","timestamp":1683049751666,"user_tz":-330,"elapsed":68,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["de_word2ix = {word: i for i, word in enumerate(de_vocab)}\n","de_ix2word = {i: word for i, word in enumerate(de_vocab)}\n","en_word2ix = {word: i for i, word in enumerate(en_vocab)}\n","en_ix2word = {i: word for i, word in enumerate(en_vocab)}"],"metadata":{"id":"sxS12PwcfODe","executionInfo":{"status":"ok","timestamp":1683049751666,"user_tz":-330,"elapsed":67,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["def tensor(list):\n","  return torch.from_numpy(np.array(list))"],"metadata":{"id":"uyD16CrbsjaI","executionInfo":{"status":"ok","timestamp":1683049751667,"user_tz":-330,"elapsed":66,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["def de_generate_index(line):\n","  new_line=[]\n","  sent=tokenise(line)\n","  for x in sent:\n","   new_line.append(de_word2ix[x])\n","  return tensor(new_line)"],"metadata":{"id":"h2ZlzhKafWkP","executionInfo":{"status":"ok","timestamp":1683049751668,"user_tz":-330,"elapsed":66,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["def en_generate_index(line):\n","  new_line=[]\n","  sent=tokenise(line)\n","  for x in sent:\n","   new_line.append(en_word2ix[x])\n","  return tensor(new_line)"],"metadata":{"id":"SbfnOCsHirF7","executionInfo":{"status":"ok","timestamp":1683049751668,"user_tz":-330,"elapsed":66,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["len(train_input),len(train_target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKj9tOgJejxw","executionInfo":{"status":"ok","timestamp":1683049751668,"user_tz":-330,"elapsed":65,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"9c572c45-e60f-4ad9-b83d-72a345d4b516"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 1000)"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["input=train_input\n","target=train_target"],"metadata":{"id":"jYIRh8qcizn6","executionInfo":{"status":"ok","timestamp":1683049751669,"user_tz":-330,"elapsed":57,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["de_generate_index(input[0]),en_generate_index(target[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REjjfns1g3o1","executionInfo":{"status":"ok","timestamp":1683049751669,"user_tz":-330,"elapsed":57,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"0f608981-0a4e-497a-ca8c-eb6f9ed59118"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1841, 1055,  951, 1527]),\n"," tensor([ 823,  148, 1086,  749,  458,   56, 1081,  269]))"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["def longest_seq(corpus):\n","  c=len(tokenise(corpus[0]))\n","  for sent in corpus:\n","    line=tokenise(sent)\n","    if c<len(line):c=len(line)\n","  return c\n","lg=max(longest_seq(input),longest_seq(target))\n","lg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiLSzCc9iK4M","executionInfo":{"status":"ok","timestamp":1683049751669,"user_tz":-330,"elapsed":51,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"355da4e0-0651-4e24-fbcd-ef0f271c7f5e"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["def pad(line,longest_seq_length):\n","  pad=torch.zeros((longest_seq_length-len(line)))\n","  return torch.cat((line,pad))"],"metadata":{"id":"ULnFVAFjh5wP","executionInfo":{"status":"ok","timestamp":1683049751670,"user_tz":-330,"elapsed":48,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["a=list(tokenise(target[0]))\n","a.append('p')\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68yUNqZsZpVH","executionInfo":{"status":"ok","timestamp":1683049751670,"user_tz":-330,"elapsed":48,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"4c923d5b-d3c4-4def-9554-47936a6c278b"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<sos>', 'i', 'dont', 'care', 'what', 'you', 'say', '<eos>', 'p']"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["def pad_sent(line):\n","  a=list(tokenise(line))\n","  for i in range(lg-len(a)):\n","    a.append('<pad>')\n","  return a\n","\n","pad_sent(target[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h149mnvAZLK5","executionInfo":{"status":"ok","timestamp":1683049751671,"user_tz":-330,"elapsed":43,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"d2571619-7378-4548-e11f-d04bb7bb4d9a"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<sos>',\n"," 'i',\n"," 'dont',\n"," 'care',\n"," 'what',\n"," 'you',\n"," 'say',\n"," '<eos>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>',\n"," '<pad>']"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["def de_index(batch,batch_size):\n","  if(batch_size==1):return pad(de_generate_index(batch),lg).unsqueeze(1).type(torch.LongTensor)\n","  bs=pad(de_generate_index(batch[0]),lg)\n","  for i in range(1,batch_size):\n","    bs=torch.vstack((bs,pad(de_generate_index(batch[i]),lg)))\n","  bs=bs.permute(1,0)\n","  return bs.type(torch.LongTensor)\n","\n","def en_index(batch,batch_size):\n","  if(batch_size==1):return pad(en_generate_index(batch),lg).unsqueeze(1).type(torch.LongTensor)\n","  bs=pad(en_generate_index(batch[0]),lg)\n","  for i in range(1,batch_size):\n","    bs=torch.vstack((bs,pad(en_generate_index(batch[i]),lg)))\n","  bs=bs.permute(1,0)\n","  return bs.type(torch.LongTensor)"],"metadata":{"id":"XoOlfWl6kG1l","executionInfo":{"status":"ok","timestamp":1683049751671,"user_tz":-330,"elapsed":40,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["de_index(input[:5],5).shape,de_index(input[0],1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-bMG6hcj656","executionInfo":{"status":"ok","timestamp":1683049751673,"user_tz":-330,"elapsed":42,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"bb64928b-5ee9-41cf-aa47-03c6239c24a4"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([22, 5]), torch.Size([22, 1]))"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["def initialize_embeddings(de_vocab_size,en_vocab_size ,embedding_dim):\n","    \"\"\"\n","    Initialize source and target embeddings\n","    \n","    Args:\n","    vocab_size: size of the vocabulary\n","    embedding_dim: size of the embedding dimension\n","    \n","    Returns:\n","    source_embed: source embedding layer\n","    target_embed: target embedding layer\n","    \"\"\"\n","    \n","    # initialize source embedding layer\n","    source_embed = nn.Embedding(de_vocab_size, embedding_dim)\n","    \n","    # initialize target embedding layer\n","    target_embed = nn.Embedding(en_vocab_size, embedding_dim)\n","    \n","    # return source and target embeddings\n","    return source_embed, target_embed"],"metadata":{"id":"sb6ffWWXqMWB","executionInfo":{"status":"ok","timestamp":1683049751673,"user_tz":-330,"elapsed":38,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["source_embed, target_embed = initialize_embeddings(de_vocab_size=len(de_vocab),en_vocab_size=len(en_vocab), embedding_dim=10)"],"metadata":{"id":"2gFrcH4vqSaJ","executionInfo":{"status":"ok","timestamp":1683049751674,"user_tz":-330,"elapsed":38,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["target_embed(en_index(target[:5],5))"],"metadata":{"id":"leoG1I8QmJKO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683049751674,"user_tz":-330,"elapsed":38,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"77e0eb3c-b7cf-494d-8e25-3a5e0b57e6fe"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.5236, -1.5899,  2.4777,  ..., -0.5857, -0.9114, -0.5862],\n","         [ 0.5236, -1.5899,  2.4777,  ..., -0.5857, -0.9114, -0.5862],\n","         [ 0.5236, -1.5899,  2.4777,  ..., -0.5857, -0.9114, -0.5862],\n","         [ 0.5236, -1.5899,  2.4777,  ..., -0.5857, -0.9114, -0.5862],\n","         [ 0.5236, -1.5899,  2.4777,  ..., -0.5857, -0.9114, -0.5862]],\n","\n","        [[ 1.1399,  1.4239, -0.4426,  ...,  2.2362,  1.5027,  0.6351],\n","         [-0.6569,  0.6391,  0.5776,  ..., -0.4920, -0.5370, -0.7822],\n","         [-0.0512, -0.6869,  1.1995,  ...,  1.0416, -0.5122,  1.2388],\n","         [ 1.5079,  0.9764,  0.6924,  ...,  0.0760,  0.6000, -0.7063],\n","         [ 0.2427, -0.0870, -1.8900,  ..., -0.1658,  0.2836, -0.0509]],\n","\n","        [[ 0.5204, -0.1418, -0.0350,  ...,  1.3545, -0.8827, -1.2806],\n","         [-0.1117, -0.7663, -1.3556,  ...,  0.7127, -1.6404, -0.0037],\n","         [ 0.3090, -0.9324, -0.4897,  ...,  1.7445,  0.6132, -0.5866],\n","         [ 0.2396, -0.8466,  1.5135,  ...,  1.8494,  0.3410,  1.5955],\n","         [-0.2336, -0.0138, -0.0866,  ...,  0.1474, -1.8464, -0.1284]],\n","\n","        ...,\n","\n","        [[ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031]],\n","\n","        [[ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031]],\n","\n","        [[ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031],\n","         [ 1.0507,  0.0563,  0.7495,  ..., -1.4908,  0.2117,  0.2031]]],\n","       grad_fn=<EmbeddingBackward0>)"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["input_seq = input[:5]\n","conv = nn.Conv1d(in_channels=10, out_channels=lg, kernel_size=3)\n","r=nn.ReLU()\n","pool = nn.MaxPool1d(3)\n","fc = nn.Linear(32, 5)\n","em=source_embed(de_index(input_seq,5)).permute(1,2,0)\n","p=pool(r(conv(em)))\n","out = F.pad(p, (4, 0, 0, 0, 0, 0))\n","p.shape,out.shape,em.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Aw5jaDCw4Sr","executionInfo":{"status":"ok","timestamp":1683049751675,"user_tz":-330,"elapsed":36,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"e2d40179-7906-4329-d654-4801ea902c65"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([5, 22, 6]), torch.Size([5, 22, 10]), torch.Size([5, 10, 22]))"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["em=torch.ones((22,5,10))\n","conv = nn.Conv1d(in_channels=10, out_channels=22, kernel_size=3)\n","pool=nn.MaxPool1d(3)\n","pol=pool(conv(em.permute(1,2,0)))\n","F.pad(pol, (4, 0, 0, 0, 0, 0)).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHcnGfUpThPI","executionInfo":{"status":"ok","timestamp":1683049751675,"user_tz":-330,"elapsed":31,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"outputId":"15bd6335-f950-48f2-fdbf-1f177b3e69a2"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 22, 10])"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size,num_layers,encoder_dropout):\n","        super(Encoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers=num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size,num_layers, bidirectional=True)\n","        self.dropout=nn.Dropout(encoder_dropout)\n","        self.lin_hid=nn.Linear(hidden_size*2,hidden_size)\n","        self.lin_cell=nn.Linear(hidden_size*2,hidden_size)\n","        self.conv = nn.Conv1d(in_channels=input_size, out_channels=lg, kernel_size=3)\n","        self.tanh=nn.Tanh()\n","        self.pool = nn.MaxPool1d(3)\n","        self.fc = nn.Linear(32, 5)\n","    def forward(self, input_seq,batch_size):\n","        #embedded=seq_len,batchsize,embeddingsize\n","        embedded = self.dropout(source_embed(de_index(input_seq,batch_size))).permute(1,2,0)#22,5,10-->5,10,22\n","        pool_out=self.pool(self.tanh(self.conv(embedded)))\n","        #conv(embedded)=5,22,20\n","        #pool=5,22,6\n","        embedded= F.pad(pool_out, (4, 0, 0, 0, 0, 0)).permute(1,0,2)#5,22,10-->22,5,10\n","        output, (hidden, cell) = self.lstm(embedded)\n","        hidden = self.lin_hid(torch.cat((hidden[0:1],hidden[1:2]), dim=2))\n","        cell = self.lin_cell(torch.cat((cell[0:1],cell[1:2]), dim=2))\n","        return output, hidden, embedded\n","        #output=seq_len,batchsize,2*hiddensize\n","        #hidden=2*numlayers,batchsizze,hiddensize=128\n","        #cell=2*numlayers,batchsizze,hiddensize=128"],"metadata":{"id":"S278NxVFrJEa","executionInfo":{"status":"ok","timestamp":1683049751675,"user_tz":-330,"elapsed":28,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# Create an instance of the Encoder model with the pre-trained embedding matrix\n","encoder = Encoder(input_size=10, hidden_size=128,num_layers=1,encoder_dropout=0.5)\n","input_seq = input[:5] # example input sequence of shape (batch_size, sequence_length)\n","encoder_output, encoder_hidden, encoder_cell = encoder(input_seq,5)\n","encoder_output.shape,encoder_hidden.shape,encoder_cell.shape"],"metadata":{"id":"Qr4Fb9MyldO9","executionInfo":{"status":"ok","timestamp":1683049752673,"user_tz":-330,"elapsed":1025,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd8233d1-727c-4a4d-b974-76299c8d0648"},"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([22, 5, 256]), torch.Size([1, 5, 128]), torch.Size([22, 5, 10]))"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self,input_size,hidden_size, output_size, num_layers,decoder_dropout):\n","        super(Decoder, self).__init__()\n","\n","        self.num_layers=num_layers\n","        self.lstm = nn.LSTM(hidden_size*2+input_size, hidden_size, num_layers, batch_first=False)\n","        \n","        self.output_layer = nn.Linear(hidden_size, output_size)\n","        self.tanh=nn.Tanh()\n","        self.softmax=nn.Softmax(dim=0)\n","        self.energy=nn.Linear(hidden_size*3,1)#hidden_size*2+hidden_size\n","        self.dropout=nn.Dropout(decoder_dropout)\n","    def forward(self, input_seq, encoder_output,encoder_hidden,encoder_cell):\n","        #input_seq:shape=batchsize\n","        #input_seq.unsqeeze(0):shape=1,batchsize\n","        embedded = self.dropout(target_embed(input_seq.unsqueeze(0)))#1,batchsize,embeddingsize=10\n","        attn_hidden = encoder_hidden.repeat(lg,1,1)\n","        energy = self.tanh(self.energy(torch.cat((attn_hidden, encoder_output),dim=2)))\n","        attention= self.softmax(energy)\n","        attention=attention.permute(1,2,0)\n","        #torch.bmm(attention,encoder_output.permute(1,0,2))=5,1,31*5,31,256=5,1,256\n","        context=torch.bmm(attention,encoder_output.permute(1,0,2)).permute(1,0,2)\n","        new_input=torch.cat((context,embedded),dim=2)\n","\n","        output, (hidden, cell) = self.lstm(new_input, (encoder_hidden, encoder_cell))\n","\n","        # Pass the LSTM output through the output layer to get the output\n","        pred = self.output_layer(output)\n","        pred.squeeze(0)\n","        return pred,hidden,cell\n","        #prde=output=1,en_vocabsize\n","        #hidden=num_layers,hiddensize\n","        #cell=num_layers,hiddensize"],"metadata":{"id":"jMp1MDfZjjtN","executionInfo":{"status":"ok","timestamp":1683050734202,"user_tz":-330,"elapsed":924,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self,input_size,hidden_size, output_size, num_layers,decoder_dropout):\n","        super(Decoder, self).__init__()\n","\n","        self.num_layers=num_layers\n","        self.lstm = nn.LSTM(hidden_size*2+input_size, hidden_size, num_layers, batch_first=False)\n","        \n","        self.output_layer = nn.Linear(hidden_size, output_size)\n","        self.relu=nn.ReLU()\n","        self.softmax=nn.Softmax(dim=0)\n","        self.energy=nn.Linear(hidden_size*3,1)#hidden_size*2+hidden_size\n","        self.dropout=nn.Dropout(decoder_dropout)\n","    def forward(self, input_seq, encoder_output,encoder_hidden,encoder_cell):\n","        #input_seq:shape=batchsize\n","        #input_seq.unsqeeze(0):shape=1,batchsize\n","        embedded = self.dropout(target_embed(input_seq.unsqueeze(0)))#1,batchsize,embeddingsize=10\n","        attn_hidden = encoder_hidden.repeat(lg,1,1)\n","        energy = self.relu(self.energy(torch.cat((attn_hidden, encoder_output),dim=2)))\n","        attention= self.softmax(energy)\n","        attention=attention.permute(1,2,0)\n","        #torch.bmm(attention,encoder_output.permute(1,0,2))=5,1,31*5,31,256=5,1,256\n","        context=torch.bmm(attention,encoder_output.permute(1,0,2)).permute(1,0,2)\n","        new_input=torch.cat((context,embedded),dim=2)\n","\n","        output, (hidden, cell) = self.lstm(new_input, (encoder_hidden, encoder_cell))\n","\n","        # Pass the LSTM output through the output layer to get the output\n","        pred = self.output_layer(output)\n","        pred.squeeze(0)\n","        return pred,hidden,cell\n","        #prde=output=1,en_vocabsize\n","        #hidden=num_layers,hiddensize\n","        #cell=num_layers,hiddensize"],"metadata":{"id":"gKY9aOA0pcXa","executionInfo":{"status":"ok","timestamp":1683050881545,"user_tz":-330,"elapsed":1232,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(input_size=10, hidden_size=128, output_size=len(en_vocab), num_layers=1,decoder_dropout=0.5)\n","input_seq = en_index(target[:5],5)[0] # replace with your input\n"," # use the final hidden state from the encoder\n","decoder_output, decoder_hidden,decoder_cell = decoder(input_seq,encoder_output, encoder_hidden,encoder_cell)\n","decoder_output.shape,decoder_hidden.shape,decoder_cell.shape"],"metadata":{"id":"3NnqoeH8s2f-","executionInfo":{"status":"error","timestamp":1683050884335,"user_tz":-330,"elapsed":10,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"8d9e33bf-162f-4b02-fcda-7e0f9b8b02cd"},"execution_count":119,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-119-e02d7737d22d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# replace with your input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;31m# use the final hidden state from the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-118-cf91c1e728b8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, encoder_output, encoder_hidden, encoder_cell)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnew_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Pass the LSTM output through the output layer to get the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    731\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    732\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[0;32m--> 733\u001b[0;31m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n\u001b[0m\u001b[1;32m    734\u001b[0m                                'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    237\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[1] size (1, 5, 128), got [22, 5, 10]"]}]},{"cell_type":"code","source":["encoder = Encoder(input_size=10, hidden_size=128,num_layers=1,encoder_dropout=0.5)\n","input_seq = input[5] # example input sequence of shape (batch_size, sequence_length)\n","encoder_output, encoder_hidden, encoder_cell = encoder(input_seq,1)\n","encoder_output.shape,encoder_hidden.shape,encoder_cell.shape\n","decoder = Decoder(input_size=10, hidden_size=128, output_size=len(en_vocab), num_layers=1,decoder_dropout=0.5)\n","trg_seq = en_index(target[5],1)[0] # replace with your input\n"," # use the final hidden state from the encoder\n","decoder_output, decoder_hidden,decoder_cell = decoder(trg_seq,encoder_output, encoder_hidden,encoder_cell)\n","decoder_output.shape,decoder_hidden.shape,decoder_cell.shape"],"metadata":{"id":"cpz-txmVe_ny","executionInfo":{"status":"aborted","timestamp":1683049752676,"user_tz":-330,"elapsed":26,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_ix2word[torch.IntTensor.item(torch.argmax(decoder_output))]"],"metadata":{"id":"PvCaEFnQAEiy","executionInfo":{"status":"aborted","timestamp":1683049752677,"user_tz":-330,"elapsed":27,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trg_seq.shape"],"metadata":{"id":"hju6VOBwo6UF","executionInfo":{"status":"aborted","timestamp":1683049752678,"user_tz":-330,"elapsed":27,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, target_seq,batch_size):\n","        target_len = lg\n","        target_vocab_size = len(en_vocab)\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n","        encoder_output, encoder_hidden, encoder_cell = self.encoder(input_seq,batch_size)\n","        decoder_input = target_seq[0]\n","        for t in range(1, target_len):\n","            output, hidden, cell = self.decoder(decoder_input,encoder_output, encoder_hidden, encoder_cell)\n","            outputs[t] = output\n","            decoder_input = target_seq[t]\n","        return outputs#shape=seq_len,batchsize,en_vocabsize"],"metadata":{"id":"4vq34dU7jnKr","executionInfo":{"status":"aborted","timestamp":1683049752678,"user_tz":-330,"elapsed":27,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(input_size=10, hidden_size=128,num_layers=1,encoder_dropout=0.5)\n","decoder = Decoder(input_size=10, hidden_size=128, output_size=len(en_vocab), num_layers=1,decoder_dropout=0.5)\n","model=Seq2Seq(encoder,decoder)\n","\n","out=model(input[:5],en_index(target[:5],5),batch_size=5)\n","out.shape"],"metadata":{"id":"gciAl9WrHmf3","executionInfo":{"status":"aborted","timestamp":1683049752679,"user_tz":-330,"elapsed":26,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.argmax(out[1][0])"],"metadata":{"id":"bvWolSsWBNl0","executionInfo":{"status":"aborted","timestamp":1683049752679,"user_tz":-330,"elapsed":26,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs= 3\n","learning_rate = 0.001\n","batch_size = 5"],"metadata":{"id":"NNVGWKdAH5Mm","executionInfo":{"status":"aborted","timestamp":1683049752680,"user_tz":-330,"elapsed":27,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(input_size=10, hidden_size=1024,num_layers=1,encoder_dropout=0.5)\n","decoder = Decoder(input_size=10, hidden_size=1024, output_size=len(en_vocab), num_layers=1,decoder_dropout=0.5)\n","model=Seq2Seq(encoder,decoder)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"1AJL-EW9H1a8","executionInfo":{"status":"aborted","timestamp":1683049752680,"user_tz":-330,"elapsed":26,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_target_tensor(target_sentence,batch_size):\n","    \n","    target_tensor = torch.zeros(batch_size,len(en_vocab))\n","    for n in range(batch_size):\n","      target=en_index(target_sentence[n],1)\n","      for i,word in enumerate(target):\n","        target_tensor[n][torch.IntTensor.item(word)]=1\n","    target_tensor=target_tensor.type(torch.long)\n","    return target_tensor"],"metadata":{"id":"B6lV8xS0y6VQ","executionInfo":{"status":"aborted","timestamp":1683049752682,"user_tz":-330,"elapsed":28,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_target_tensor(target[:5],5).shape"],"metadata":{"id":"nvWtFdP79fF4","executionInfo":{"status":"aborted","timestamp":1683049752683,"user_tz":-330,"elapsed":29,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn(out.permute(1,0,2),create_target_tensor(target[:5],5))"],"metadata":{"id":"Kq8Nf7QX925e","executionInfo":{"status":"aborted","timestamp":1683049752684,"user_tz":-330,"elapsed":30,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Driving training loop\n","BATCH=30\n","model.train()\n","#for epoch in tqdm(range(1,num_epochs+1)):\n","for epoch in range(3):\n","    total_epoch_loss=0\n","    # Iterate through train dataset\n","    for i in range(0,961,BATCH):\n","        # 1. forward pass the inputs through the model\n","        output =model(input[i:i+BATCH],en_index(target[i:i+BATCH],BATCH),batch_size=BATCH).permute(1,0,2)\n","        trg=create_target_tensor(target[i:i+BATCH],BATCH)\n","\n","        optimizer.zero_grad()\n","        \n","        loss = loss_fn(output,trg)                                 \n","        total_epoch_loss += loss.item()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n","        # 4. update the parameters\n","        optimizer.step()\n","        print(i)\n","\n","    print(f\"Epoch: [{epoch}/{num_epochs}] Epoch Loss: {total_epoch_loss}\")"],"metadata":{"id":"YIQ_O9jngHec","executionInfo":{"status":"aborted","timestamp":1683049752685,"user_tz":-330,"elapsed":30,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_output,encoder_hidden, encoder_cell = model.encoder(input[998],1)\n","output, hidden, cell = model.decoder(torch.tensor(7177).unsqueeze(0),encoder_output,encoder_hidden,encoder_cell)"],"metadata":{"id":"XMdxH-OmCZ_h","executionInfo":{"status":"aborted","timestamp":1683049752686,"user_tz":-330,"elapsed":31,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_ix2word[torch.IntTensor.item(torch.argmax(output[0][0]))]"],"metadata":{"id":"no4bbrWECyp_","executionInfo":{"status":"aborted","timestamp":1683049752688,"user_tz":-330,"elapsed":33,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_word2ix['<sos>']"],"metadata":{"id":"M3s-OJyCEgdL","executionInfo":{"status":"aborted","timestamp":1683049752689,"user_tz":-330,"elapsed":33,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input[0]"],"metadata":{"id":"jdkSxpUMq5dQ","executionInfo":{"status":"aborted","timestamp":1683049752689,"user_tz":-330,"elapsed":33,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translate_sentence(model, sentence,max_length=lg):\n","\n","\n","    with torch.no_grad():\n","        encoder_output,encoder_hidden, encoder_cell = model.encoder(sentence,1)\n","    out=[89]\n","    for i in range(max_length):\n","        previous_word = torch.tensor(out[-1])\n","\n","        with torch.no_grad():\n","            output, hidden, cell = model.decoder(previous_word.unsqueeze(0),encoder_output,encoder_hidden,encoder_cell)\n","            best_guess=torch.IntTensor.item(torch.argmax(output[0][0]))\n","        out.append(best_guess)\n","\n","        if torch.IntTensor.item(torch.argmax(output[0][0])) == en_word2ix['<eos>']:\n","            break\n","\n","    translated_sen = [en_ix2word[idx] for idx in out]\n","\n","    return translated_sen[1:]"],"metadata":{"id":"pgBEOIhyFqaT","executionInfo":{"status":"aborted","timestamp":1683049752690,"user_tz":-330,"elapsed":34,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent=input[9]\n","translate_sentence(model,sent)"],"metadata":{"id":"mjrcz84jwdFB","executionInfo":{"status":"aborted","timestamp":1683049752690,"user_tz":-330,"elapsed":33,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a"],"metadata":{"id":"ECt20W_2rmOr","executionInfo":{"status":"aborted","timestamp":1683049752691,"user_tz":-330,"elapsed":34,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(a)):\n","  a[i]='<pad>'\n","a,pad_sent(target[0])"],"metadata":{"id":"Hu-76aUXaN6h","executionInfo":{"status":"aborted","timestamp":1683049752691,"user_tz":-330,"elapsed":34,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleu_score(a, pad_sent(target[989]))"],"metadata":{"id":"H8fIvu2uY3AU","executionInfo":{"status":"aborted","timestamp":1683049752692,"user_tz":-330,"elapsed":35,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchtext.data.metrics import bleu_score"],"metadata":{"id":"deJhA2FRN_jF","executionInfo":{"status":"aborted","timestamp":1683049752693,"user_tz":-330,"elapsed":36,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bleu(data, model, german, english, device):\n","    targets= []\n","    outputs= []\n","\n","    for eg in data:\n","        src = vars(eg)['src']\n","        trg = var(eg)['trg']\n","\n","        prediction = translate_sentence(model, src, german, english, device)\n","        prediction = prediction[:-1] # eos removed\n","\n","        targets.append([trg])\n","        outputs.append(prediction)\n","\n","    return bleu_score(outputs, targets)"],"metadata":{"id":"liEqin8uN7Zs","executionInfo":{"status":"aborted","timestamp":1683049752695,"user_tz":-330,"elapsed":37,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","trg=trg.type(torch.LongTensor)\n","out=out.type(torch.LongTensor)\n","scores = torch.zeros((31,5,10612))  # shape: (batch_size=10, num_classes=5)\n","labels = torch.ones((31,5,10612),dtype=torch.long)  # shape: (batch_size=10)\n","\n","# Define the cross-entropy loss function\n","\n","# Compute the loss\n","loss_fn(scores, labels)\n","'''"],"metadata":{"id":"ZD-kuhxD83jL","executionInfo":{"status":"aborted","timestamp":1683049752696,"user_tz":-330,"elapsed":38,"user":{"displayName":"VAIBHAV VIKAS","userId":"11898623521982249815"}}},"execution_count":null,"outputs":[]}]}